{
    "cells": [
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# Model Training\n## Introduction\n\nThis notebook is using a simple dataset for epitope prediction used in vaccine development from the Kaggle COVID-19/SARS B-cell Epitope Prediction data which cloned on a Github repository for the sake of this project. This notebook will go through the following steps:\n1. Load Training set\n2. Determine optimal hyperparameters for classifier\n3. Train an MLP Classifier model\n"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Setup"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "## Environment libraries\nimport os, types\nimport ibm_boto3\nfrom botocore.client import Config\nimport warnings\n\n## Data processing libraries\nimport numpy as np\nimport pandas as pd\n\n## Plot libraries\n#import matplotlib.pyplot as plt\n\n## Machine learning classifier and tools\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV\n\n## Performance metric libraries\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.model_selection import GridSearchCV",
            "execution_count": 1,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Handle warnings\nwarnings.filterwarnings('ignore')  # \"error\", \"ignore\", \"always\", \"default\", \"module\", \"always\" or \"once\"",
            "execution_count": 2,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Load Training Data"
        },
        {
            "metadata": {
                "scrolled": false
            },
            "cell_type": "code",
            "source": "def __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share the notebook.\n\nif os.environ.get('RUNTIME_ENV_LOCATION_TYPE') == 'external':\n    endpoint_d5592f3b715a4ab696c8411b475cdae6 = 'https://s3-api.us-geo.objectstorage.softlayer.net'\nelse:\n    endpoint_d5592f3b715a4ab696c8411b475cdae6 = 'https://s3-api.us-geo.objectstorage.service.networklayer.com'\n\nclient_d5592f3b715a4ab696c8411b475cdae6 = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='qDV6Rk1jMFRAdD1sFE2uZh2tpbGIpHsvc66ObIULfDQ8',\n    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url=endpoint_d5592f3b715a4ab696c8411b475cdae6)\n\nbody = client_d5592f3b715a4ab696c8411b475cdae6.get_object(Bucket='covid19epitopeprediction-donotdelete-pr-vjiedfg7ztqsrx',Key='train_data.csv')['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n\ndf = pd.read_csv(body)\ndf.head()",
            "execution_count": 3,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 3,
                    "data": {
                        "text/plain": "   peptide_length  chou_fasman     emini  kolaskar_tongaonkar    parker  \\\n0             0.0     0.476285  0.017313             0.431655  0.619814   \n1             0.0     0.233202  0.004408             0.865707  0.284809   \n2             0.0     0.314229  0.084398             0.292566  0.733319   \n3             0.0     0.865613  0.062751             0.235012  0.845722   \n4             0.0     0.671937  0.046989             0.237410  0.753154   \n\n   isoelectric_point  aromaticity  hydrophobicity  stability  kmeans_feature  \\\n0           0.248550     0.566651        0.564298   0.264627        0.000000   \n1           0.295412     0.359258        0.597317   0.148556        0.333333   \n2           0.530951     0.503623        0.880225   0.170325        0.333333   \n3           0.064573     0.245679        0.447703   0.192377        0.333333   \n4           0.372240     0.569787        0.429961   0.123374        0.333333   \n\n   target  \n0       1  \n1       1  \n2       1  \n3       1  \n4       1  ",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>peptide_length</th>\n      <th>chou_fasman</th>\n      <th>emini</th>\n      <th>kolaskar_tongaonkar</th>\n      <th>parker</th>\n      <th>isoelectric_point</th>\n      <th>aromaticity</th>\n      <th>hydrophobicity</th>\n      <th>stability</th>\n      <th>kmeans_feature</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.476285</td>\n      <td>0.017313</td>\n      <td>0.431655</td>\n      <td>0.619814</td>\n      <td>0.248550</td>\n      <td>0.566651</td>\n      <td>0.564298</td>\n      <td>0.264627</td>\n      <td>0.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.233202</td>\n      <td>0.004408</td>\n      <td>0.865707</td>\n      <td>0.284809</td>\n      <td>0.295412</td>\n      <td>0.359258</td>\n      <td>0.597317</td>\n      <td>0.148556</td>\n      <td>0.333333</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.314229</td>\n      <td>0.084398</td>\n      <td>0.292566</td>\n      <td>0.733319</td>\n      <td>0.530951</td>\n      <td>0.503623</td>\n      <td>0.880225</td>\n      <td>0.170325</td>\n      <td>0.333333</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.865613</td>\n      <td>0.062751</td>\n      <td>0.235012</td>\n      <td>0.845722</td>\n      <td>0.064573</td>\n      <td>0.245679</td>\n      <td>0.447703</td>\n      <td>0.192377</td>\n      <td>0.333333</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.671937</td>\n      <td>0.046989</td>\n      <td>0.237410</td>\n      <td>0.753154</td>\n      <td>0.372240</td>\n      <td>0.569787</td>\n      <td>0.429961</td>\n      <td>0.123374</td>\n      <td>0.333333</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Model Optimization and Evaluation\nAfter several iterative steps, the model was shown to perform slightly better using LBFGS gradient descent with 50-100-50 layers."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Create variable and target training and testing arrays\nX = df.drop(['target'], axis = 1).to_numpy()\ny = df['target'].to_numpy()",
            "execution_count": 4,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "X_train,X_test,y_train,y_test = train_test_split(X,y,stratify=y,test_size=0.3,random_state=0)",
            "execution_count": 5,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Instantiate the machine learning classifier\nmlp = MLPClassifier(max_iter=100)",
            "execution_count": 6,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Select hyperparameter space search\nparameter_space = {\n    'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n    'activation': ['tanh', 'relu'],\n    'solver': ['sgd', 'lbfgs'],\n    'alpha': [0.0001, 0.05],\n    'learning_rate': ['constant','adaptive'],\n}",
            "execution_count": 7,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Perform hyperparameter search\nclf = GridSearchCV(mlp, parameter_space, n_jobs=-1, cv=3)\nclf.fit(X_train, y_train)",
            "execution_count": 8,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 8,
                    "data": {
                        "text/plain": "GridSearchCV(cv=3, estimator=MLPClassifier(max_iter=100), n_jobs=-1,\n             param_grid={'activation': ['tanh', 'relu'],\n                         'alpha': [0.0001, 0.05],\n                         'hidden_layer_sizes': [(50, 50, 50), (50, 100, 50),\n                                                (100,)],\n                         'learning_rate': ['constant', 'adaptive'],\n                         'solver': ['sgd', 'lbfgs']})"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Show dbst paramete set\nprint('Best parameters found:\\n', clf.best_params_)\n\n## Show all results\n#means = clf.cv_results_['mean_test_score']\n#stds = clf.cv_results_['std_test_score']\n#for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n#    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))",
            "execution_count": 9,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Best parameters found:\n {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'lbfgs'}\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Instantiate the machine learning classifiers\nmlp = MLPClassifier(activation = 'relu', hidden_layer_sizes=(50, 100, 50), max_iter=1000, alpha=1e-4, solver='lbfgs', random_state=42, learning_rate = 'adaptive', learning_rate_init=.1)",
            "execution_count": 14,
            "outputs": []
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "# Train model\nmlp.fit(X_train,y_train)\nprint(\"Training set score: %f\" % mlp.score(X_train, y_train))",
            "execution_count": 15,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Training set score: 0.840809\n",
                    "name": "stdout"
                }
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.7",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.7.10",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}